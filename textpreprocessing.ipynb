{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63be2548-68a0-490b-beb6-cb6f5b57ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fahee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Natural', 'Language', 'Toolkit', '(', 'NLTK', ')', 'is', 'one', 'of', 'the', 'largest', 'Python', 'libraries', 'for', 'performing', 'various', 'Natural', 'Language', 'Processing', 'tasks', '.', 'From', 'rudimentary', 'tasks', 'such', 'as', 'text', 'pre-processing', 'to', 'tasks', 'like', 'vectorized', 'representation', 'of', 'text', '–', 'NLTK', '’', 's', 'API', 'has', 'covered', 'everything', '.']\n",
      "\n",
      "Sentences: ['Natural Language Toolkit (NLTK) is one of the largest Python \\nlibraries for performing various Natural Language Processing tasks.', 'From rudimentary tasks such as text pre-processing to tasks like \\nvectorized representation of text – NLTK’s API has covered everything.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"\"\"Natural Language Toolkit (NLTK) is one of the largest Python \n",
    "libraries for performing various Natural Language Processing tasks. \n",
    "From rudimentary tasks such as text pre-processing to tasks like \n",
    "vectorized representation of text – NLTK’s API has covered everything.\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Words:\", words)\n",
    "print(\"\\nSentences:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef11e3ec-0613-4ee9-be06-499e9a27cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fahee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Text: ['Natural', 'Language', 'Toolkit', '(', 'NLTK', ')', 'works', 'powerful', 'Python', 'library', 'wide', 'range', 'tools', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '.', 'fundamental', 'tasks', 'like', 'text', 'pre-processing', 'advanced', 'operations', 'semantic', 'reasoning', ',', 'NLTK', 'provides', 'versatile', 'API', 'caters', 'diverse', 'needs', 'language-related', 'tasks', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"\"\"Natural Language Toolkit (NLTK) works as a powerful Python \n",
    "library that a wide range of tools for Natural Language Processing \n",
    "(NLP). From fundamental tasks like text pre-processing to more \n",
    "advanced operations such as semantic reasoning, NLTK provides a \n",
    "versatile API that caters to the diverse needs of language-related \n",
    "tasks.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = word_tokenize(text)\n",
    "filtered_text = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Filtered Text:\", filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75a32cf-e156-4060-9737-217e97fd291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: let’s eat grandma \n",
      "grandma let’s eat \n",
      "silvia are you free tomorrow \n",
      "yes i’m free on saturday\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"\"\"Let’s eat, Grandma! \n",
    "Grandma, Let’s eat! \n",
    "Silvia, Are you free tomorrow? \n",
    "Yes, I’m free on Saturday.\"\"\"\n",
    "\n",
    "cleaned_text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54501a4c-4a32-4243-8f95-e6bb9c5993c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: Natural Language Processing NLP is a field of AI that focuses on enabling computers to understand interpret generate human language NLP includes tasks like tokenization lemmatization sentiment analysis It helps in applications such as chatbots machine translation and voice assistants However cleaning textremoving extra spaces punctuations special charactersis crucial Without preprocessing NLP models may not perform accurately So can you clean this messy text make it structured\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\" @@Natural   Language Processing (NLP)!!!  is a    field of AI that  \n",
    "focuses on  ...     \n",
    "   enabling computers to understand,    interpret, & generate   human  \n",
    "language.   \n",
    " NLP   includes  tasks like *tokenization, lemmatization,*  && \n",
    "sentiment analysis.     \n",
    " It  helps in   applications such as chatbots,   machine translation,  \n",
    "and   voice assistants!!!   \n",
    " However,   cleaning text—removing   extra spaces, punctuations, && \n",
    "special $$$ characters—is crucial.     \n",
    " Without   preprocessing,  NLP models may not    perform    \n",
    "accurately !!!     \n",
    " So,   can you clean this   messy text & make  it    structured???   \"\"\"\n",
    "\n",
    "cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra spaces\n",
    "\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92e15fa-de9b-445a-8973-010ba92e24d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fahee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\fahee\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['the', 'research', 'are', 'analyz', 'variou', 'dataset', 'to', 'studi', 'the', 'effect', 'of', 'autom', '.', 'they', 'observ', 'that', 'autom', 'system', 'perform', 'task', 'more', 'effici', 'than', 'human', '.', 'mani', 'industri', 'have', 'been', 'adopt', 'ai-driven', 'solut', 'to', 'improv', 'product', '.', 'run', 'complex', 'algorithm', 'help', 'in', 'predict', 'futur', 'trend', 'accur', '.', 'sever', 'compani', 'are', 'invest', 'in', 'develop', 'smarter', 'and', 'more', 'adapt', 'model', '.', 'data', 'scientist', 'continu', 'refin', 'their', 'model', 'to', 'achiev', 'better', 'perform', '.', 'the', 'advanc', 'in', 'technolog', 'have', 'transform', 'the', 'way', 'busi', 'oper', '.']\n",
      "\n",
      "Lemmatized Words: ['The', 'researcher', 'are', 'analyzing', 'various', 'datasets', 'to', 'study', 'the', 'effect', 'of', 'automation', '.', 'They', 'observed', 'that', 'automated', 'system', 'perform', 'task', 'more', 'efficiently', 'than', 'human', '.', 'Many', 'industry', 'have', 'been', 'adopting', 'AI-driven', 'solution', 'to', 'improve', 'productivity', '.', 'Running', 'complex', 'algorithm', 'help', 'in', 'predicting', 'future', 'trend', 'accurately', '.', 'Several', 'company', 'are', 'investing', 'in', 'developing', 'smarter', 'and', 'more', 'adaptive', 'model', '.', 'Data', 'scientist', 'continuously', 'refine', 'their', 'model', 'to', 'achieve', 'better', 'performance', '.', 'The', 'advancement', 'in', 'technology', 'have', 'transformed', 'the', 'way', 'business', 'operate', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"\"\"The researchers are analyzing various datasets to study the effects \n",
    "of automation. They observed that automated systems perform tasks more \n",
    "efficiently than humans. Many industries have been adopting AI-driven \n",
    "solutions to improve productivity. Running complex algorithms helps in \n",
    "predicting future trends accurately. Several companies are investing in \n",
    "developing smarter and more adaptive models. Data scientists continuously \n",
    "refine their models to achieve better performance. The advancements in \n",
    "technology have transformed the way businesses operate.\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "print(\"\\nLemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55b6f2-9baf-4c0f-aa57-67a004b74719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
